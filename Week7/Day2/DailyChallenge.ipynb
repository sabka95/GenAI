{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "883be0380bf948aaabf4d006b57bdbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_472819ff98fa43e0993b9f63cc96dfc5",
              "IPY_MODEL_456a378cf201417a86732dd013fed8bc",
              "IPY_MODEL_7457b9a3c97e48eda941008eb32d95fd"
            ],
            "layout": "IPY_MODEL_b5bfa6cf93ad4b6d9745ccd6e4b071ce"
          }
        },
        "472819ff98fa43e0993b9f63cc96dfc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8658e6da08654f80abaa4402fb74428b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b3bab130683436195ffae77e6452be7",
            "value": "Map: 100%"
          }
        },
        "456a378cf201417a86732dd013fed8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78fa37492e6e4659b3789ebad552e445",
            "max": 251,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74f494513085483ebaaf30f9edb95605",
            "value": 251
          }
        },
        "7457b9a3c97e48eda941008eb32d95fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6d835296b24ac596817e410e3d9d36",
            "placeholder": "​",
            "style": "IPY_MODEL_feb8baa2e5c5410e9c23e311f27cd3a7",
            "value": " 251/251 [00:00&lt;00:00, 3891.11 examples/s]"
          }
        },
        "b5bfa6cf93ad4b6d9745ccd6e4b071ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8658e6da08654f80abaa4402fb74428b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3bab130683436195ffae77e6452be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78fa37492e6e4659b3789ebad552e445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f494513085483ebaaf30f9edb95605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a6d835296b24ac596817e410e3d9d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb8baa2e5c5410e9c23e311f27cd3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paRHTtBNFhtY",
        "outputId": "9f2cd63f-3697-4c0d-f610-b6a4d0e893be"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Install necessary libraries (PEFT, datasets) :**"
      ],
      "metadata": {
        "id": "D8RmkMuy3GwX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "alOFwyooKJHv"
      },
      "outputs": [],
      "source": [
        "!pip install --q peft==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "3inEwlmTN6kM"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load a pre-trained language model (bigscience/bloomz-560m) and its tokenizer :**"
      ],
      "metadata": {
        "id": "XCnjx7ef3MVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bigscience/bloomz-560m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0m6aqJUOQU6",
        "outputId": "1ebdacfa-ead0-44b8-c4c6-d2e4a39002ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the dataset and preprocess it for the model :**"
      ],
      "metadata": {
        "id": "dZ1h5ApM3P-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"Abirate/english_quotes\", split=\"train[:10%]\")"
      ],
      "metadata": {
        "id": "dGRuw-q5S1E3"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "PilMVZDYVMe6",
        "outputId": "1f32a002-b6f8-4018-d7ea-1efe36fd21ee"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 691);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcuOeNLZVPL1",
        "outputId": "6eb80645-4dfb-42bb-a361-30da21b37542"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['quote', 'author', 'tags'],\n",
            "    num_rows: 251\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcwhzhVmVzpC",
        "outputId": "8bf0d28c-9714-4583-fafe-c0f8b67c27e4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'quote': '“Be yourself; everyone else is already taken.”',\n",
              " 'author': 'Oscar Wilde',\n",
              " 'tags': ['be-yourself',\n",
              "  'gilbert-perreira',\n",
              "  'honesty',\n",
              "  'inspirational',\n",
              "  'misattributed-oscar-wilde',\n",
              "  'quote-investigator']}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(lambda x: tokenizer(x[\"quote\"], padding=True, truncation=True), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "883be0380bf948aaabf4d006b57bdbed",
            "472819ff98fa43e0993b9f63cc96dfc5",
            "456a378cf201417a86732dd013fed8bc",
            "7457b9a3c97e48eda941008eb32d95fd",
            "b5bfa6cf93ad4b6d9745ccd6e4b071ce",
            "8658e6da08654f80abaa4402fb74428b",
            "9b3bab130683436195ffae77e6452be7",
            "78fa37492e6e4659b3789ebad552e445",
            "74f494513085483ebaaf30f9edb95605",
            "0a6d835296b24ac596817e410e3d9d36",
            "feb8baa2e5c5410e9c23e311f27cd3a7"
          ]
        },
        "id": "Xv-bEk0D1vn1",
        "outputId": "c02fdad0-686f-4e6b-dca1-0689ecd6f59e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/251 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "883be0380bf948aaabf4d006b57bdbed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.remove_columns([\"quote\", \"author\", \"tags\"])"
      ],
      "metadata": {
        "id": "_os0oMV-Ol7Y"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCB3jPIB5DYx",
        "outputId": "0a1ee25d-9aaa-4715-fab7-e2556f841c65"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  1502,\n",
              "  17143,\n",
              "  33218,\n",
              "  30,\n",
              "  39839,\n",
              "  4384,\n",
              "  632,\n",
              "  11226,\n",
              "  15713,\n",
              "  17,\n",
              "  982],\n",
              " 'attention_mask': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1]}"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure LoRA using LoraConfig :**"
      ],
      "metadata": {
        "id": "8nSgfJdg5Xcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in model.named_modules():\n",
        "  print(\"name :\", name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itZS7JVt7kZq",
        "outputId": "fb03d086-6c05-4eac-b3b8-df050a418408"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name : \n",
            "name : transformer\n",
            "name : transformer.word_embeddings\n",
            "name : transformer.word_embeddings_layernorm\n",
            "name : transformer.h\n",
            "name : transformer.h.0\n",
            "name : transformer.h.0.input_layernorm\n",
            "name : transformer.h.0.self_attention\n",
            "name : transformer.h.0.self_attention.query_key_value\n",
            "name : transformer.h.0.self_attention.dense\n",
            "name : transformer.h.0.self_attention.attention_dropout\n",
            "name : transformer.h.0.post_attention_layernorm\n",
            "name : transformer.h.0.mlp\n",
            "name : transformer.h.0.mlp.dense_h_to_4h\n",
            "name : transformer.h.0.mlp.gelu_impl\n",
            "name : transformer.h.0.mlp.dense_4h_to_h\n",
            "name : transformer.h.1\n",
            "name : transformer.h.1.input_layernorm\n",
            "name : transformer.h.1.self_attention\n",
            "name : transformer.h.1.self_attention.query_key_value\n",
            "name : transformer.h.1.self_attention.dense\n",
            "name : transformer.h.1.self_attention.attention_dropout\n",
            "name : transformer.h.1.post_attention_layernorm\n",
            "name : transformer.h.1.mlp\n",
            "name : transformer.h.1.mlp.dense_h_to_4h\n",
            "name : transformer.h.1.mlp.gelu_impl\n",
            "name : transformer.h.1.mlp.dense_4h_to_h\n",
            "name : transformer.h.2\n",
            "name : transformer.h.2.input_layernorm\n",
            "name : transformer.h.2.self_attention\n",
            "name : transformer.h.2.self_attention.query_key_value\n",
            "name : transformer.h.2.self_attention.dense\n",
            "name : transformer.h.2.self_attention.attention_dropout\n",
            "name : transformer.h.2.post_attention_layernorm\n",
            "name : transformer.h.2.mlp\n",
            "name : transformer.h.2.mlp.dense_h_to_4h\n",
            "name : transformer.h.2.mlp.gelu_impl\n",
            "name : transformer.h.2.mlp.dense_4h_to_h\n",
            "name : transformer.h.3\n",
            "name : transformer.h.3.input_layernorm\n",
            "name : transformer.h.3.self_attention\n",
            "name : transformer.h.3.self_attention.query_key_value\n",
            "name : transformer.h.3.self_attention.dense\n",
            "name : transformer.h.3.self_attention.attention_dropout\n",
            "name : transformer.h.3.post_attention_layernorm\n",
            "name : transformer.h.3.mlp\n",
            "name : transformer.h.3.mlp.dense_h_to_4h\n",
            "name : transformer.h.3.mlp.gelu_impl\n",
            "name : transformer.h.3.mlp.dense_4h_to_h\n",
            "name : transformer.h.4\n",
            "name : transformer.h.4.input_layernorm\n",
            "name : transformer.h.4.self_attention\n",
            "name : transformer.h.4.self_attention.query_key_value\n",
            "name : transformer.h.4.self_attention.dense\n",
            "name : transformer.h.4.self_attention.attention_dropout\n",
            "name : transformer.h.4.post_attention_layernorm\n",
            "name : transformer.h.4.mlp\n",
            "name : transformer.h.4.mlp.dense_h_to_4h\n",
            "name : transformer.h.4.mlp.gelu_impl\n",
            "name : transformer.h.4.mlp.dense_4h_to_h\n",
            "name : transformer.h.5\n",
            "name : transformer.h.5.input_layernorm\n",
            "name : transformer.h.5.self_attention\n",
            "name : transformer.h.5.self_attention.query_key_value\n",
            "name : transformer.h.5.self_attention.dense\n",
            "name : transformer.h.5.self_attention.attention_dropout\n",
            "name : transformer.h.5.post_attention_layernorm\n",
            "name : transformer.h.5.mlp\n",
            "name : transformer.h.5.mlp.dense_h_to_4h\n",
            "name : transformer.h.5.mlp.gelu_impl\n",
            "name : transformer.h.5.mlp.dense_4h_to_h\n",
            "name : transformer.h.6\n",
            "name : transformer.h.6.input_layernorm\n",
            "name : transformer.h.6.self_attention\n",
            "name : transformer.h.6.self_attention.query_key_value\n",
            "name : transformer.h.6.self_attention.dense\n",
            "name : transformer.h.6.self_attention.attention_dropout\n",
            "name : transformer.h.6.post_attention_layernorm\n",
            "name : transformer.h.6.mlp\n",
            "name : transformer.h.6.mlp.dense_h_to_4h\n",
            "name : transformer.h.6.mlp.gelu_impl\n",
            "name : transformer.h.6.mlp.dense_4h_to_h\n",
            "name : transformer.h.7\n",
            "name : transformer.h.7.input_layernorm\n",
            "name : transformer.h.7.self_attention\n",
            "name : transformer.h.7.self_attention.query_key_value\n",
            "name : transformer.h.7.self_attention.dense\n",
            "name : transformer.h.7.self_attention.attention_dropout\n",
            "name : transformer.h.7.post_attention_layernorm\n",
            "name : transformer.h.7.mlp\n",
            "name : transformer.h.7.mlp.dense_h_to_4h\n",
            "name : transformer.h.7.mlp.gelu_impl\n",
            "name : transformer.h.7.mlp.dense_4h_to_h\n",
            "name : transformer.h.8\n",
            "name : transformer.h.8.input_layernorm\n",
            "name : transformer.h.8.self_attention\n",
            "name : transformer.h.8.self_attention.query_key_value\n",
            "name : transformer.h.8.self_attention.dense\n",
            "name : transformer.h.8.self_attention.attention_dropout\n",
            "name : transformer.h.8.post_attention_layernorm\n",
            "name : transformer.h.8.mlp\n",
            "name : transformer.h.8.mlp.dense_h_to_4h\n",
            "name : transformer.h.8.mlp.gelu_impl\n",
            "name : transformer.h.8.mlp.dense_4h_to_h\n",
            "name : transformer.h.9\n",
            "name : transformer.h.9.input_layernorm\n",
            "name : transformer.h.9.self_attention\n",
            "name : transformer.h.9.self_attention.query_key_value\n",
            "name : transformer.h.9.self_attention.dense\n",
            "name : transformer.h.9.self_attention.attention_dropout\n",
            "name : transformer.h.9.post_attention_layernorm\n",
            "name : transformer.h.9.mlp\n",
            "name : transformer.h.9.mlp.dense_h_to_4h\n",
            "name : transformer.h.9.mlp.gelu_impl\n",
            "name : transformer.h.9.mlp.dense_4h_to_h\n",
            "name : transformer.h.10\n",
            "name : transformer.h.10.input_layernorm\n",
            "name : transformer.h.10.self_attention\n",
            "name : transformer.h.10.self_attention.query_key_value\n",
            "name : transformer.h.10.self_attention.dense\n",
            "name : transformer.h.10.self_attention.attention_dropout\n",
            "name : transformer.h.10.post_attention_layernorm\n",
            "name : transformer.h.10.mlp\n",
            "name : transformer.h.10.mlp.dense_h_to_4h\n",
            "name : transformer.h.10.mlp.gelu_impl\n",
            "name : transformer.h.10.mlp.dense_4h_to_h\n",
            "name : transformer.h.11\n",
            "name : transformer.h.11.input_layernorm\n",
            "name : transformer.h.11.self_attention\n",
            "name : transformer.h.11.self_attention.query_key_value\n",
            "name : transformer.h.11.self_attention.dense\n",
            "name : transformer.h.11.self_attention.attention_dropout\n",
            "name : transformer.h.11.post_attention_layernorm\n",
            "name : transformer.h.11.mlp\n",
            "name : transformer.h.11.mlp.dense_h_to_4h\n",
            "name : transformer.h.11.mlp.gelu_impl\n",
            "name : transformer.h.11.mlp.dense_4h_to_h\n",
            "name : transformer.h.12\n",
            "name : transformer.h.12.input_layernorm\n",
            "name : transformer.h.12.self_attention\n",
            "name : transformer.h.12.self_attention.query_key_value\n",
            "name : transformer.h.12.self_attention.dense\n",
            "name : transformer.h.12.self_attention.attention_dropout\n",
            "name : transformer.h.12.post_attention_layernorm\n",
            "name : transformer.h.12.mlp\n",
            "name : transformer.h.12.mlp.dense_h_to_4h\n",
            "name : transformer.h.12.mlp.gelu_impl\n",
            "name : transformer.h.12.mlp.dense_4h_to_h\n",
            "name : transformer.h.13\n",
            "name : transformer.h.13.input_layernorm\n",
            "name : transformer.h.13.self_attention\n",
            "name : transformer.h.13.self_attention.query_key_value\n",
            "name : transformer.h.13.self_attention.dense\n",
            "name : transformer.h.13.self_attention.attention_dropout\n",
            "name : transformer.h.13.post_attention_layernorm\n",
            "name : transformer.h.13.mlp\n",
            "name : transformer.h.13.mlp.dense_h_to_4h\n",
            "name : transformer.h.13.mlp.gelu_impl\n",
            "name : transformer.h.13.mlp.dense_4h_to_h\n",
            "name : transformer.h.14\n",
            "name : transformer.h.14.input_layernorm\n",
            "name : transformer.h.14.self_attention\n",
            "name : transformer.h.14.self_attention.query_key_value\n",
            "name : transformer.h.14.self_attention.dense\n",
            "name : transformer.h.14.self_attention.attention_dropout\n",
            "name : transformer.h.14.post_attention_layernorm\n",
            "name : transformer.h.14.mlp\n",
            "name : transformer.h.14.mlp.dense_h_to_4h\n",
            "name : transformer.h.14.mlp.gelu_impl\n",
            "name : transformer.h.14.mlp.dense_4h_to_h\n",
            "name : transformer.h.15\n",
            "name : transformer.h.15.input_layernorm\n",
            "name : transformer.h.15.self_attention\n",
            "name : transformer.h.15.self_attention.query_key_value\n",
            "name : transformer.h.15.self_attention.dense\n",
            "name : transformer.h.15.self_attention.attention_dropout\n",
            "name : transformer.h.15.post_attention_layernorm\n",
            "name : transformer.h.15.mlp\n",
            "name : transformer.h.15.mlp.dense_h_to_4h\n",
            "name : transformer.h.15.mlp.gelu_impl\n",
            "name : transformer.h.15.mlp.dense_4h_to_h\n",
            "name : transformer.h.16\n",
            "name : transformer.h.16.input_layernorm\n",
            "name : transformer.h.16.self_attention\n",
            "name : transformer.h.16.self_attention.query_key_value\n",
            "name : transformer.h.16.self_attention.dense\n",
            "name : transformer.h.16.self_attention.attention_dropout\n",
            "name : transformer.h.16.post_attention_layernorm\n",
            "name : transformer.h.16.mlp\n",
            "name : transformer.h.16.mlp.dense_h_to_4h\n",
            "name : transformer.h.16.mlp.gelu_impl\n",
            "name : transformer.h.16.mlp.dense_4h_to_h\n",
            "name : transformer.h.17\n",
            "name : transformer.h.17.input_layernorm\n",
            "name : transformer.h.17.self_attention\n",
            "name : transformer.h.17.self_attention.query_key_value\n",
            "name : transformer.h.17.self_attention.dense\n",
            "name : transformer.h.17.self_attention.attention_dropout\n",
            "name : transformer.h.17.post_attention_layernorm\n",
            "name : transformer.h.17.mlp\n",
            "name : transformer.h.17.mlp.dense_h_to_4h\n",
            "name : transformer.h.17.mlp.gelu_impl\n",
            "name : transformer.h.17.mlp.dense_4h_to_h\n",
            "name : transformer.h.18\n",
            "name : transformer.h.18.input_layernorm\n",
            "name : transformer.h.18.self_attention\n",
            "name : transformer.h.18.self_attention.query_key_value\n",
            "name : transformer.h.18.self_attention.dense\n",
            "name : transformer.h.18.self_attention.attention_dropout\n",
            "name : transformer.h.18.post_attention_layernorm\n",
            "name : transformer.h.18.mlp\n",
            "name : transformer.h.18.mlp.dense_h_to_4h\n",
            "name : transformer.h.18.mlp.gelu_impl\n",
            "name : transformer.h.18.mlp.dense_4h_to_h\n",
            "name : transformer.h.19\n",
            "name : transformer.h.19.input_layernorm\n",
            "name : transformer.h.19.self_attention\n",
            "name : transformer.h.19.self_attention.query_key_value\n",
            "name : transformer.h.19.self_attention.dense\n",
            "name : transformer.h.19.self_attention.attention_dropout\n",
            "name : transformer.h.19.post_attention_layernorm\n",
            "name : transformer.h.19.mlp\n",
            "name : transformer.h.19.mlp.dense_h_to_4h\n",
            "name : transformer.h.19.mlp.gelu_impl\n",
            "name : transformer.h.19.mlp.dense_4h_to_h\n",
            "name : transformer.h.20\n",
            "name : transformer.h.20.input_layernorm\n",
            "name : transformer.h.20.self_attention\n",
            "name : transformer.h.20.self_attention.query_key_value\n",
            "name : transformer.h.20.self_attention.dense\n",
            "name : transformer.h.20.self_attention.attention_dropout\n",
            "name : transformer.h.20.post_attention_layernorm\n",
            "name : transformer.h.20.mlp\n",
            "name : transformer.h.20.mlp.dense_h_to_4h\n",
            "name : transformer.h.20.mlp.gelu_impl\n",
            "name : transformer.h.20.mlp.dense_4h_to_h\n",
            "name : transformer.h.21\n",
            "name : transformer.h.21.input_layernorm\n",
            "name : transformer.h.21.self_attention\n",
            "name : transformer.h.21.self_attention.query_key_value\n",
            "name : transformer.h.21.self_attention.dense\n",
            "name : transformer.h.21.self_attention.attention_dropout\n",
            "name : transformer.h.21.post_attention_layernorm\n",
            "name : transformer.h.21.mlp\n",
            "name : transformer.h.21.mlp.dense_h_to_4h\n",
            "name : transformer.h.21.mlp.gelu_impl\n",
            "name : transformer.h.21.mlp.dense_4h_to_h\n",
            "name : transformer.h.22\n",
            "name : transformer.h.22.input_layernorm\n",
            "name : transformer.h.22.self_attention\n",
            "name : transformer.h.22.self_attention.query_key_value\n",
            "name : transformer.h.22.self_attention.dense\n",
            "name : transformer.h.22.self_attention.attention_dropout\n",
            "name : transformer.h.22.post_attention_layernorm\n",
            "name : transformer.h.22.mlp\n",
            "name : transformer.h.22.mlp.dense_h_to_4h\n",
            "name : transformer.h.22.mlp.gelu_impl\n",
            "name : transformer.h.22.mlp.dense_4h_to_h\n",
            "name : transformer.h.23\n",
            "name : transformer.h.23.input_layernorm\n",
            "name : transformer.h.23.self_attention\n",
            "name : transformer.h.23.self_attention.query_key_value\n",
            "name : transformer.h.23.self_attention.dense\n",
            "name : transformer.h.23.self_attention.attention_dropout\n",
            "name : transformer.h.23.post_attention_layernorm\n",
            "name : transformer.h.23.mlp\n",
            "name : transformer.h.23.mlp.dense_h_to_4h\n",
            "name : transformer.h.23.mlp.gelu_impl\n",
            "name : transformer.h.23.mlp.dense_4h_to_h\n",
            "name : transformer.ln_f\n",
            "name : lm_head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=1,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ],
      "metadata": {
        "id": "F1U_qoyi5Xpk"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Apply LoRA to the pre-trained model using get_peft_model :**"
      ],
      "metadata": {
        "id": "4KWGgvLt9tQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "BWIsoG4L9vFE"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Set up training arguments using TrainingArguments :**"
      ],
      "metadata": {
        "id": "OrL1bHCP9_Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = os.path.join(\"/content/drive/MyDrive/GENAI/Week7/Day2\", \"peft_lab_outputs\")\n",
        "training_args = TrainingArguments(\n",
        "    report_to=\"none\",\n",
        "    output_dir=output_directory,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate= 3e-5,\n",
        "    num_train_epochs=5,\n",
        "    use_cpu=False\n",
        ")"
      ],
      "metadata": {
        "id": "ia9lAHif9_13"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Initialize and train the model using Trainer :**"
      ],
      "metadata": {
        "id": "0MWpvBepAhYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=data,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cymyGRj8AiPy",
        "outputId": "1cab4d7c-dab5-40aa-f712-ba127bab12a2"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "tpKi6K6QDagQ",
        "outputId": "e6f26fdf-02de-4468-bbd8-0f1695dcfe1d"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 09:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=315, training_loss=3.2785733661954364, metrics={'train_runtime': 559.1838, 'train_samples_per_second': 2.244, 'train_steps_per_second': 0.563, 'total_flos': 1243329727610880.0, 'train_loss': 3.2785733661954364, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Save the fine-tuned LoRA model :**"
      ],
      "metadata": {
        "id": "YwDEh-pMDkMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_path = os.path.join(output_directory, \"peft_model\")\n",
        "peft_model.save_pretrained(peft_model_path)"
      ],
      "metadata": {
        "id": "EfwrVR_HDhCP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Load the saved LoRA model for inference using PeftModel.from_pretrained :**"
      ],
      "metadata": {
        "id": "rczbzEQFP6m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_model_path)"
      ],
      "metadata": {
        "id": "BV7rVNYTP-Z8"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Generate text using the fine-tuned model and the tokenizer :**"
      ],
      "metadata": {
        "id": "jADElEEkQHVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"Two things are infinite: \", return_tensors=\"pt\")\n",
        "inputs = {k: v.to(peft_model.device) for k, v in inputs.items()}\n",
        "\n",
        "outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    max_length=50,\n",
        "    num_return_sequences=1,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.8,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yniKl4DxQIAK",
        "outputId": "e2d5f540-758a-4ee2-a643-34cf2f68b83d"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Two things are infinite:  time and space. But there is one thing that is not infinite: time itself.']\n"
          ]
        }
      ]
    }
  ]
}