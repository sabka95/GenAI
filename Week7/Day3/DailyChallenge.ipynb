{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Understanding LLM Evaluation:**"
      ],
      "metadata": {
        "id": "ZpnxP_afjRlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Les LLMs sont non déterministes, produisent des réponses ouvertes, et leur évaluation dépend de critères subjectifs comme la pertinence ou la sécurité.\n",
        "* Les principales raisons d'évaluer la sécurité d'un modèle est  d'éviter les dérives, limiter les biais, protéger les utilisateurs et respecter les cadres légaux et éthiques.\n",
        "* les tests adversial contribuent a l'amélioration d'un llm en identifiant des failles via des entrées piégeuses, ce qui permet de renforcer la robustesse du modèle.\n",
        "* Les métriques d'évalutions automatisées manquent de nuance et de compréhension contextuelle. L’humain reste plus fiable, mais plus lent et coûteux."
      ],
      "metadata": {
        "id": "0fAm25aLlPJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Applying BLEU and ROUGE Metrics:**"
      ],
      "metadata": {
        "id": "_zmvDaEdl4a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "V3Z2WuhGxwLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "AOs64hpIuumQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Si-fpnXjKjI",
        "outputId": "0a979fe4-5f68-430c-f518-1c3a2f5fcb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score:  0.06296221772093169\n"
          ]
        }
      ],
      "source": [
        "reference_bleu =[\"Despite the increasing reliance on artificial intelligence in various industries, human oversight remains essential to ensure ethical and effective implementation.\"]\n",
        "generated_bleu = \"Although AI is being used more in industries, human supervision is still necessary for ethical and effective application.\"\n",
        "\n",
        "ref_tokens = [reference_bleu[0].lower().split()]\n",
        "gen_tokens = generated_bleu.split()\n",
        "\n",
        "smoothie = SmoothingFunction().method1\n",
        "bleu_score = sentence_bleu(ref_tokens, gen_tokens, smoothing_function=smoothie)\n",
        "\n",
        "print(\"Bleu Score: \", bleu_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_rouge = \"In the face of rapid climate change, global initiatives must focus on reducing carbon emissions and developing sustainable energy sources to mitigate environmental impact.\"\n",
        "generated_rouge = \"To counteract climate change, worldwide efforts should aim to lower carbon emissions and enhance renewable energy development.\"\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(reference_rouge, generated_rouge)\n",
        "\n",
        "for metric, score in scores.items():\n",
        "    print(f\"{metric}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8quRVYuuWaU",
        "outputId": "8930f2a6-a691-46ae-93d1-2b334fc5a567"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1: Score(precision=0.47058823529411764, recall=0.3333333333333333, fmeasure=0.39024390243902435)\n",
            "rouge2: Score(precision=0.1875, recall=0.13043478260869565, fmeasure=0.15384615384615383)\n",
            "rougeL: Score(precision=0.35294117647058826, recall=0.25, fmeasure=0.2926829268292683)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le bleu score et le rouge score ne prennent pas en  compte le sens, ce qui pénalise les reformulations valides. Par exemple, deux phrases au sens équivalent mais avec des mots différents obtiennent un score faible. De plus, ils ne tiennent pas compte de la fluidité, de la grammaire ni de la cohérence. Ces métriques sont donc mal adaptées aux textes contextuels ou originaux.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbqyEIrC3N_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour dépasser ces limites, on peut utiliser BERTScore, qui compare le sens des phrases via des modèles de langage, ou METEOR, qui reconnaît les synonymes et les variations grammaticales. L’évaluation humaine reste essentielle pour juger la pertinence, la clarté et la créativité, surtout dans les tâches ouvertes comme le résumé, la génération de dialogue ou la narration."
      ],
      "metadata": {
        "id": "uOe3Idnf3fyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Perplexity Analysis:**"
      ],
      "metadata": {
        "id": "hMRXM_Ky3qMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_model_a = 0.8\n",
        "prob_model_b = 0.4\n",
        "\n",
        "perplexity_a = 1 / prob_model_a\n",
        "perplexity_b = 1 / prob_model_b\n",
        "\n",
        "print(\"Perplexity Model A: \", perplexity_a)\n",
        "print(\"Perplexity Model B: \", perplexity_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brl4NWv03pGX",
        "outputId": "a1c62ff4-a9b6-4bc9-af66-ce04807ef907"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Model A:  1.25\n",
            "Perplexity Model B:  2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle A a une perplexité plus faible (1,25), ce qui signifie qu’il est plus confiant et performant pour prédire le mot « mitigation ». Une faible perplexité indique une meilleure compréhension du contexte."
      ],
      "metadata": {
        "id": "f5ffIJJo5S9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modèle avec une perplexité de 100 montre une forte incertitude dans ses prédictions. Cela reflète une mauvaise performance. Pour l’améliorer, on peut enrichir les données d'entraînement, ajuster les hyperparamètres ou utiliser un modèle plus avancé et spécialisé."
      ],
      "metadata": {
        "id": "feMPN1va5iXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Human Evaluation Exercise:**"
      ],
      "metadata": {
        "id": "rxe4CrUl5N1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "j'évaluerai la fluidité de la réponse de ce chatbot a 2 sur 5 sur l'echelle de likert dû à la formulation \"comprehend I do not\" qui inverse les mots d'une phrase naturellement formulée, ce qui nuit à la fluidité de la phrase même si celle-ci reste compréhensible."
      ],
      "metadata": {
        "id": "0I3ckRtK6pSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une reformultion potentielle de la phrase pourrait être : \"Sorry, I didn’t understand. Could you rephrase your question?\". Cela rend la phrase plus fluide et plus naturelle."
      ],
      "metadata": {
        "id": "13Q2ile17e-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Adversarial Testing Exercise:**"
      ],
      "metadata": {
        "id": "zGLF89-57tuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un LLM pourrait se tromper en répondant à la question en raison de la confusion entre “capitol” et “capital”.\n",
        "Le mot “capitol” désigne généralement un batiment. Un LLM pourrait donc répondre par erreur en parlant d’un bâtiment gouvernemental plutôt que de la ville."
      ],
      "metadata": {
        "id": "hY-589p29_5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour améliorer la robustesse d’un LLM face à ce type d’erreurs, on pourrait intégrer une phase de correction orthographique et sémantique du prompt avant génération de la réponse."
      ],
      "metadata": {
        "id": "WusUTzKJ-d05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Robustesse (orthographe ou formulation étrange)\n",
        "« Quelle est la capitale de l’Allemagne de l’est ? »\n",
        "\n",
        "2. Fausse information\n",
        "« Combien de lunes a la Terre ? Trois ou quatre ? »\n",
        "\n",
        "3. Logique et déduction\n",
        "« Paul a deux fois l’âge de sa sœur. Sa sœur a 10 ans de plus que Paul. Quel âge a Paul ?"
      ],
      "metadata": {
        "id": "EmC_DL8G-qyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Comparative Analysis of Evaluation Methods:**"
      ],
      "metadata": {
        "id": "uoSzKFzT-qoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le text summarization consiste à condenser un texte tout en conservant les idées essentielles.\n",
        "\n",
        "ROUGE mesure les n-grammes communs entre le résumé généré et un résumé de référence. Il est simple et courant, mais ne reconnaît pas les reformulations.\n",
        "\n",
        "BERTScore compare le sens grâce à des modèles comme BERT. Il détecte mieux les synonymes et paraphrases, ce qui le rend plus pertinent pour les résumés sémantiquement corrects.\n",
        "\n",
        "Évaluation humaine juge la fidélité, la clarté et la fluidité. C’est la méthode la plus fiable, mais aussi la plus coûteuse."
      ],
      "metadata": {
        "id": "PFoDTUWPEH3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bien que BERTScore soit utile dans ce contexte pour évaluer si le résumé reflète bien le sens du texte original, l’évaluation humaine reste malgré tout la plus complète et la plus appropriée, car elle permet d’apprécier des aspects qualitatifs comme la clarté, la fidélité au contenu et la cohérence globale."
      ],
      "metadata": {
        "id": "qo0qi_mqEe0X"
      }
    }
  ]
}