{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "idlEQVb0M6bQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load the MNIST dataset:**"
      ],
      "metadata": {
        "id": "JuUEr3VzOOJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train),  (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH0vrwg7OMFR",
        "outputId": "d5571d6b-3bed-4756-bab0-58c7a861af74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrZeiJ0GOlz1",
        "outputId": "f23d0763-79b5-40e2-ac48-c995d404bbfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le set d'entrainement est un tensor contenant 60 000 images de dimension 28x28"
      ],
      "metadata": {
        "id": "5O6xZtkBPkxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUyDUCVuOpGB",
        "outputId": "0a3f31b1-0286-44f7-b22b-1edadca6324a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(x_train[100], cmap='gray')\n",
        "plt.title(f\"Label: {y_train[100]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "upvGfv4fOtP9",
        "outputId": "f7e76fdb-95fc-4090-869c-f2c54887789a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preprocess the data for a Fully Connected Neural Network:**"
      ],
      "metadata": {
        "id": "IvKdXdZPQ-YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw4-LA1kTHdV",
        "outputId": "47bc6260-6051-4497-a5b5-1f3a232437e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "  x_flat = x.reshape(x.shape[0], 28 * 28)\n",
        "  x_flat = x_flat.astype(np.float32) / 255.0\n",
        "  y_oh = keras.utils.to_categorical(y, 10)\n",
        "  return x_flat, y_oh"
      ],
      "metadata": {
        "id": "ixSPZckBQOFF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flat, y_train_oh = preprocess(x_train, y_train)\n",
        "x_test_flat, y_test_oh = preprocess(x_test, y_test)"
      ],
      "metadata": {
        "id": "OeKJsRSlTzek"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Build and train a Fully Connected Neural Network:**"
      ],
      "metadata": {
        "id": "zrHImhvGVo2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(256, activation='relu', input_shape = (784,)),\n",
        "    keras.layers.Dense(128,  activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duzgSJC4U-41",
        "outputId": "1ad6e911-677a-49a1-c5e4-06f9095fd535"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "rGDunSeEYYAv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train_flat,\n",
        "    y_train_oh,\n",
        "    epochs = 10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7mXrvRzYu5j",
        "outputId": "8e36a72e-3684-4278-c970-a0def26dca91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3536\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0936\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0531\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0387\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0307\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0234\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0256\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0178\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0169\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_flat, y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOhnXvCxZ0IA",
        "outputId": "b651a49b-3b05-453a-a524-b6f287a0a3a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.1030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08374987542629242, 0.9815000295639038]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle apprend efficacement dès les premières itérations, avec d’excellents résultats obtenus dès la deuxième époque. Il montre également une bonne capacité de généralisation sur les données de test."
      ],
      "metadata": {
        "id": "lnC0Z1bz5Oe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Preprocess the data for a Convolutional Neural Network:**"
      ],
      "metadata": {
        "id": "gT6MNFxJ4Z2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_cnn(x, y):\n",
        "  x_flat = x.reshape(-1, x.shape[1], x.shape[2], 1)\n",
        "  x_flat = x_flat.astype(np.float32) / 255.0\n",
        "  y_oh = keras.utils.to_categorical(y, 10)\n",
        "  return x_flat, y_oh"
      ],
      "metadata": {
        "id": "hUZqeu0d4eJR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cnn, y_train_cnn = preprocess_cnn(x_train, y_train)\n",
        "x_test_cnn, y_test_cnn = preprocess_cnn(x_test, y_test)"
      ],
      "metadata": {
        "id": "Z2m5sBn5Z9on"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Build and train a Convolutional Neural Network:**\n",
        "\n"
      ],
      "metadata": {
        "id": "yw-n8kT-Z9Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1), padding='same'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXGUsrjUaCKc",
        "outputId": "0fb0a916-d944-4ecf-cd72-1f18567a7749"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "M08YsJ6NgPqO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = cnn.fit(\n",
        "    x_train_cnn,\n",
        "    y_train_cnn,\n",
        "    epochs = 10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKWcQmOrgbNw",
        "outputId": "746a6b8c-ead9-432e-f2fd-7c144f905958"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 25ms/step - accuracy: 0.9106 - loss: 0.2942\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.9868 - loss: 0.0420\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0286\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0167\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - accuracy: 0.9960 - loss: 0.0139\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.9967 - loss: 0.0105\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0077\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0062\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0067\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Compare the performance:**"
      ],
      "metadata": {
        "id": "r0rOjVWSiGR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(x_test_cnn, y_test_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYLyVf8nh84s",
        "outputId": "8c58f806-2647-4b37-dd63-f23bc1dadb07"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.0539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04117271304130554, 0.9904000163078308]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle Fully Connected atteint une précision de 97,81 % sur le test, ce qui reste satisfaisant. Cependant, le CNN obtient une précision supérieure de 98,74 % avec une perte plus faible, confirmant sa capacité à mieux généraliser. Grâce à ses couches de convolution et de pooling, le CNN extrait plus efficacement les motifs visuels importants, ce qui en fait un modèle plus adapté pour la classification d’images comme celles du dataset MNIST."
      ],
      "metadata": {
        "id": "1BmTcoEjmBq-"
      }
    }
  ]
}