{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setup : Install required packages datasets, evaluate and transformers[sentencepiece].**\n",
        "\n"
      ],
      "metadata": {
        "id": "uIrQuVqXN8xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "9OMUEsYyOBbD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Load & Inspect Dataset :**"
      ],
      "metadata": {
        "id": "PxkHhsEEQoSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet -U datasets"
      ],
      "metadata": {
        "id": "ZwAvIG4BUVZ-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "raw = load_dataset(\"sms_spam\")\n",
        "\n",
        "\n",
        "train_ds = raw['train'].shuffle(seed=42).select(range(4000))\n",
        "val_ds   = raw['train'].shuffle(seed=42).select(range(4000, 5000))\n",
        "\n",
        "train_ds.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZkzznKEQrBb",
        "outputId": "006913c1-da77-43bd-a59a-4259fc8422fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sms': Value('string'), 'label': ClassLabel(names=['ham', 'spam'])}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Tokenization :**"
      ],
      "metadata": {
        "id": "VYV7ktVWVMj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer"
      ],
      "metadata": {
        "id": "mEPTgn2FVQUI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"\n",
        "tokenizer  = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_fn(examples):\n",
        "\n",
        "    return tokenizer(\n",
        "        examples[\"sms\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
        "val_tok   = val_ds.map(tokenize_fn, batched=True)"
      ],
      "metadata": {
        "id": "8rJHBNi5T0Zc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Initialization**"
      ],
      "metadata": {
        "id": "fH_4LhAnqIlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW-hQUnqqIXY",
        "outputId": "5dc39f3b-621a-4a79-8873-6cbcf8eb380c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Metrics Definition**"
      ],
      "metadata": {
        "id": "8U8pMO1Vr0eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy  = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall    = evaluate.load(\"recall\")\n",
        "f1        = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision\": precision.compute(predictions=preds, references=labels, average = \"binary\")[\"precision\"],\n",
        "        \"recall\":    recall.compute(predictions=preds, references=labels, average = \"binary\")[\"recall\"],\n",
        "        \"f1\":        f1.compute(predictions=preds, references=labels, average = \"binary\")[\"f1\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "O2pH3qi9rysJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans un jeu de données déséquilibré comme SMS spam (avec beaucoup plus de \"ham\" que de \"spam\"), l'accuracy seule peut être trompeuse : un modèle qui prédit toujours \"ham\" aura une bonne accuracy sans détecter les spams. Suivre aussi la précision et le recall est essentiel. Un modèle avec une haute accuracy mais un faible rappel sur le spam signifie qu’il rate beaucoup de spams : il est trop prudent et en laisse passer, ce qui est problématique pour la détection."
      ],
      "metadata": {
        "id": "mrMzsjK6wGKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. TrainingArguments Configuration**"
      ],
      "metadata": {
        "id": "M33GV6AZwKrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/results\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    logging_dir=\"/content/logs\",\n",
        "    logging_steps=500,\n",
        "\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    report_to=None,\n",
        "    save_total_limit=1,\n",
        ")"
      ],
      "metadata": {
        "id": "Mh2KoXN9wJ84"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le weight_decay limite la taille des poids du modèle pour éviter l’overfitting. Une valeur plus élevée est utile si le modèle apprend trop bien les données d’entraînement mais généralise mal. Une valeur plus basse est utile si le dataset est petit ou si le modèle a du mal à apprendre."
      ],
      "metadata": {
        "id": "_X2ZwKSKyJqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afpbl9lZ0Fp8",
        "outputId": "c69b61f1-a612-4f87-de6b-31d72917910a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Train & Evaluate**"
      ],
      "metadata": {
        "id": "xfPWDXwRyKP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "AR-_5c5syMwG",
        "outputId": "87d85105-16e1-4fb7-d76d-8bcc96e2655d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 03:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.115000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.026700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.03444773703813553, 'eval_accuracy': 0.993, 'eval_precision': 0.991304347826087, 'eval_recall': 0.95, 'eval_f1': 0.9702127659574468, 'eval_runtime': 3.9394, 'eval_samples_per_second': 253.845, 'eval_steps_per_second': 31.731, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle est très performant. Il prédit correctement dans 99,3 % des cas. Il identifie presque tous les spams (rappel 95 %) et se trompe très peu quand il dit qu’un message est un spam (précision 99,1 %). Le F1-score de 97 % montre un bon équilibre entre les deux."
      ],
      "metadata": {
        "id": "5IVmsF0s1_nN"
      }
    }
  ]
}